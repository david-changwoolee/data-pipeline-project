#Data Pipeline 구축 토이 프로젝트
===========================

### 프로젝트 개요
* Hadoop, Hive, Spark, Airflow 등 Data Engineering 기술들을 이용하여 데이터 파이프라인 구축한다.
* 인터넷으로부터 데이터를 받아 처리하는 ETL 파이프라인을 구현한다.
* Local 컴퓨터 위에 Docker 로 구현한 분산 환경에서 프로젝트를 진행한다.
* 장애 발생을 대비한 고가용성(High Availability) 기능을 추가한다.
* Hadoop 에 데이터를 저장하고(Data Lake, Data Warehouse) Spark 로 데이터를 처리하고(ETL) Hive 에 데이터를 넣는다(Data Mart).

#### 추가 구현 옵션
* Grafana 등을 사용하여 데이터 Monitoring Dashboard 를 제작한다.
* 프로젝트 완료 후에는 실제 업무에 사용한다는 가정 하에 장애/부하 테스트를 진행하고, 기능 최적화를 한다.
* 사용한 코드 및 기술을 Github 에 모두 업로드하고 설명을 덧붙인다.

### 목적
* Bigdata Engineer 로서 전문성을 키운다.
* 다양한 Bigdata Platform 을 익힌다.
